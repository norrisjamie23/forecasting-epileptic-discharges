{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "burning-burst",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv1D, MaxPooling1D, BatchNormalization, Activation\n",
    "from tensorflow.keras.activations import relu\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.metrics import Accuracy, AUC\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "moving-donna",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4320, 20480)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.load('y.npy')\n",
    "y = 1 * (y > 2)\n",
    "\n",
    "X = np.load('X.npy')\n",
    "X.shape\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "y_train = y_train.reshape(y_train.shape[0], 1)\n",
    "y_test = y_test.reshape(y_test.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "technological-lover",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts = np.bincount(y_test[:, 0])\n",
    "\n",
    "# weight_for_0 = 1.0 / counts[0]\n",
    "# weight_for_1 = 1.0 / counts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "meaning-chase",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(445, 419)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape\n",
    "np.sum(y_test > 0), np.sum(y_test <= 0)\n",
    "# np.sum(y_train > 2), np.sum(y_train <= 2)\n",
    "# 310/(310+266) = 53.8%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "analyzed-armenia",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 20479, 8)          24        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 20479, 8)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5119, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 5118, 16)          272       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5118, 16)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1279, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1278, 16)          528       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1278, 16)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 159, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 158, 8)            264       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 158, 8)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 19, 8)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 152)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                7650      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 8,789\n",
      "Trainable params: 8,789\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor=\"val_auc\", patience=20, baseline=0.5, mode='max', restore_best_weights=True)\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(filters=8, kernel_size=2, input_shape=X_train[0].shape))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Activation(relu))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "\n",
    "model.add(Conv1D(filters=16, kernel_size=2))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Activation(relu))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "          \n",
    "model.add(Conv1D(filters=16, kernel_size=2))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Activation(relu))\n",
    "model.add(MaxPooling1D(pool_size=8))\n",
    "\n",
    "model.add(Conv1D(filters=8, kernel_size=2))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Activation(relu))\n",
    "model.add(MaxPooling1D(pool_size=8))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Activation(relu))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[AUC()])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "absent-catholic",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 6s 70ms/step - loss: 0.3610 - auc: 0.9199 - val_loss: 0.6258 - val_auc: 0.7943\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "history = model.fit(X_train, y_train, epochs=1, validation_split=0.2, callbacks=[es])#, class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "catholic-angola",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import roc_auc_score, plot_roc_curve, roc_curve\n",
    "# import matplotlib.pyplot as plt\n",
    "# import scikitplot as skplt\n",
    "\n",
    "# # roc_auc = roc_auc_score(y_test, model.predict_proba(X_test))\n",
    "# # skplt.metrics.plot_roc_curve(y_test, model.predict_proba(X_test))\n",
    "# # plt.show()\n",
    "# metrics.roc_curve(y_test, model.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "centered-watershed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test), pos_label=2)\n",
    "# plt.plot(fpr, tpr, 'g', alpha=0.15)\n",
    "# plt.xlim([-0.01, 1.01])\n",
    "# plt.ylim([-0.01, 1.01])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
